![Logo_CompassoUOL_Positivo](https://user-images.githubusercontent.com/94761781/212589731-3d9e9380-e9ea-4ea2-9f52-fc6595f8d3f0.png)
# Avalia√ß√£o Sprint 8 - Programa de Bolsas Compass.uol / AWS e IFCE

## üìù Objetivo

Esse projeto tem como objetivo a cria√ß√£o um conjunto de fun√ß√µes lambda que possam ser usadas para acessar as APIs respons√°veis por processar imagens usando o servi√ßo de reconhecimento visual da AWS, o "Rekognition". Essas fun√ß√µes ser√£o usadas para extrair tags de imagens armazenadas no servi√ßo de armazenamento da AWS, o S3. Para acompanhar e registrar os resultados dessas fun√ß√µes, ser√° utilizado o servi√ßo de monitoramento da AWS, o CloudWatch.
<br/>

## ‚öôÔ∏è Tecnologias

* [Rekognition](https://aws.amazon.com/pt/rekognition/)
* [AWS Lambda](https://aws.amazon.com/pt/lambda/)
* [CloudWatch](https://aws.amazon.com/pt/cloudwatch/)
* [Amazon S3](https://aws.amazon.com/pt/s3/) 
<br/>

## üîÄ Entendendo as rotas

ROTA 1 ‚Üí J√° implementada no projeto.

ROTA 2 ‚Üí J√° implementada no projeto.

ROTA 3 ‚Üí J√° implementada no projeto.

ROTA 4 ‚Üí Ap√≥s a imagem ser armazenada no servi√ßo S3, o aplicativo far√° uma chamada para o servi√ßo Rekognition. O resultado dessa chamada, que estar√° contido no corpo da resposta, dever√° ser registrado na aplica√ß√£o por meio do servi√ßo CloudWatch.

ROTA 5 ‚Üí Implementar o upload de imagens hospedadas no servi√ßo S3, √© preciso incluir novos campos que indiquem se a imagem cont√©m rostos e sua localiza√ß√£o na imagem. Para obter essas informa√ß√µes, √© necess√°rio utilizar um modelo de identifica√ß√£o de faces do servi√ßo Rekognition. Para isso, basta fazer uma chamada ao servi√ßo Rekognition durante o processo de upload da imagem e registrar os resultados no CloudWatch da aplica√ß√£o. Dessa forma, √© poss√≠vel monitorar as informa√ß√µes geradas pela an√°lise e utilizar esses dados para aprimorar as funcionalidades da aplica√ß√£o.

ROTA 6 ‚Üí Para realizar a tarefa de detectar a emo√ß√£o principal em uma imagem carregada manualmente no Amazon S3, √© necess√°rio implementar novos campos de retorno na chamada do modelo de identifica√ß√£o de faces do Rekognition. A resposta da chamada deve ser registrada no CloudWatch e exibir todas as emo√ß√µes detectadas, caso haja mais de uma face na imagem. Para realizar essa tarefa, o primeiro passo √© fazer o upload manual da imagem no Amazon S3. Em seguida, √© preciso chamar o servi√ßo Rekognition para identificar as emo√ß√µes detectadas em cada face presente na imagem. Depois disso, √© necess√°rio implementar novos campos de retorno que indiquem a emo√ß√£o principal detectada pelo modelo de identifica√ß√£o de faces do Rekognition. Esses campos devem ser registrados no CloudWatch para monitoramento e an√°lise. Ao final, o resultado da chamada do servi√ßo Rekognition deve ser exibido na aplica√ß√£o, mostrando todas as emo√ß√µes detectadas caso haja mais de uma face na imagem. Com essas informa√ß√µes, os usu√°rios poder√£o ter uma melhor compreens√£o das emo√ß√µes presentes na imagem e tomar decis√µes mais informadas com base nesses dados.
<br/>


## üö´ Impedimentos
-
-
-
<br/>

## ‚úîÔ∏è Conclus√£o

O projeto utiliza a plataforma AWS com Amazon Rekognition, S3 e CloudWatch. Com o Amazon Rekognition, temos a capacidade de analisar precisamente imagens e v√≠deos para detectar e reconhecer objetos, o que nos traz um gama gigantesca de possibilidades fornecidas por essa ferramenta. Usando o CloudWatch em conjunto com o Amazon Rekognition, √© poss√≠vel monitorar e visualizar m√©tricas importantes, para o pleno funcionamento da aplica√ß√£o desenvolvida.
<br/>

## üë• Equipe

* [Rosemelry](https://github.com/Rosemelry)
* [Julio Cesar](https://github.com/JC-Rodrigues)
* [Samara Alcantara](https://github.com/SamaraAlcantara)
* [Jhonnatan Gon√ßalves](https://github.com/jhonatangoncalvespereira)
