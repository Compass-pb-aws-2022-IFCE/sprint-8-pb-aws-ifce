![Logo_CompassoUOL_Positivo](https://user-images.githubusercontent.com/94761781/212589731-3d9e9380-e9ea-4ea2-9f52-fc6595f8d3f0.png)
# üìë Avalia√ß√£o Sprint 8 - Programa de Bolsas Compass.uol / AWS e IFCE

## üìå T√≥picos 

- [üìù Descri√ß√£o do projeto](#-descri√ß√£o-do-projeto)

- [üíª Ferramentas e Tecnologias](#-ferramentas-e-tecnologias)

- [üòå Impedimentos resolvidos](#-impedimentos-resolvidos)

- [üìÇ Organiza√ß√£o do c√≥digo](#-organiza√ß√£o-do-c√≥digo)

- [‚¨áÔ∏è Arquivo Functions.py](#-arquivo-functions.py)

- [‚öôÔ∏è Estrutura das rotas](#-estrutura-das-rotas)

- [üì§ Deploy](#deploy)

- [üìå Considera√ß√µes finais](#-considera√ß√µes-finais)

## üìù Descri√ß√£o do projeto

Elabora√ß√£o de um conjunto de fun√ß√µes lambda que oferecer√£o suporte a APIs respons√°veis por executar o servi√ßo de "rekognition" e extrair tags de imagens hospedadas no S3. Al√©m disso, utilizar o CloudWatch para registrar os registros dos resultados obtidos.

Sendo:

| ROTA   | M√âTODO HTTP | ARQUITETURA |
| ---    | ---         | --- |
| ROTA 1 | GET         | Definida no escopo do projeto, status code para sucesso da requisi√ß√£o ser√° 200. |
| ROTA 2 | GET         | Definida no escopo do projeto, status code para sucesso da requisi√ß√£o ser√° 200. |
| ROTA 3 | GET         | Definida no escopo do projeto, status code para sucesso da requisi√ß√£o ser√° 200.    |
| ROTA 4 | POST        | Com a imagem hospedada no S3, o post ir√° chamar o Rekognition e o resultado(body) da chamada deve estar logado na aplica√ß√£o atrav√©s do CloudWatch. |
| ROTA 5 | POST        | Implementar o post de uma imagem hospedada no S3, √© necess√°rio adicionar novos campos de retorno que informem se a imagem cont√©m algum rosto e sua posi√ß√£o. Para isso, √© preciso utilizar um modelo de identifica√ß√£o de faces do servi√ßo Rekognition. O post deve chamar o Rekognition para realizar a an√°lise e o resultado da chamada (body) deve ser registrado na aplica√ß√£o por meio do CloudWatch |
| ROTA 6 | POST        | Fazer o upload manual de uma imagem no S3 e implementar novos campos de retorno que indiquem a emo√ß√£o principal detectada pelo modelo de identifica√ß√£o de faces do Rekognition. O resultado da chamada deve ser registrado na aplica√ß√£o por meio do CloudWatch, exibindo todas as emo√ß√µes detectadas caso haja mais de uma face na imagem. O post deve chamar o servi√ßo Rekognition para obter essa informa√ß√£o. |

## üíª Ferramentas e tecnologias

- Visual Studio Code;
- Amazon Web Services(AWS Lambda, S3, Rekognition, Serverless);
- Python;
- Postman.

## üòå Impedimentos resolvidos

- Interpreta√ß√£o inicial da constru√ß√£o, organiza√ß√£o do c√≥digo como tamb√©m de sua arquitetura em cada rota.
- Erro na inser√ß√£o das credenciais e execu√ß√£o do comando  ```"serverless config credentials" ```, resolvido ap√≥s pesquisa e altera√ß√£o do  ```"Set-ExecutionPolicy" ``` para o status de ```"RemoteSigned" ``` no PowerShell.
- Constru√ß√£o das rotas, como tamb√©m a sua "successfully executed", cada rota haviam erros que foram resolvidos ap√≥s reuni√µes,estudo e pequisa.

## üìÇ Organiza√ß√£o do c√≥digo

![Pastas](https://i.imgur.com/5g0uunU.png)

Acima √© o demonstrativo de como foi organizado o projeto e subdivido em pastas conforme era a atua√ß√£o do c√≥digo.

A organiza√ß√£o do c√≥digo ajudou a evitar erros e bugs, uma vez que as partes do c√≥digo est√£o claramente separadas e identificadas. Ela tamb√©m facilitou a implementa√ß√£o de novas funcionalidades e a resolu√ß√£o de problemas, pois se tornou mais f√°cil localizar e corrigir o c√≥digo relevante.

Em resumo, a organiza√ß√£o do c√≥digo foi fundamental para o sucesso do projeto, pois tornou o processo de desenvolvimento mais eficiente e efetivo.

## ‚¨áÔ∏è Arquivo Functions.py

C√≥digo em Python que define quatro fun√ß√µes para trabalhar com imagens na AWS: 

```bash
- validate_image_info(); 
- get_labels_response();
- get_faces_response();
- get_image_creation_date(). 
```
Essas fun√ß√µes utilizam os m√≥dulos boto3, json e datetime para se comunicar com servi√ßos os da AWS, validar informa√ß√µes de imagem, obter informa√ß√µes de r√≥tulos e faces de uma imagem, e obter a data de cria√ß√£o de uma imagem em um bucket do S3.

## ‚öôÔ∏è Estrutura das rotas

### **V1 (ROTA 4)**

Fun√ß√£o Lambda que recebe um evento e um contexto e retorna uma resposta em formato JSON contendo informa√ß√µes sobre uma imagem.

A fun√ß√£o principal, "v1_vision", tenta obter informa√ß√µes sobre uma imagem a partir do evento recebido. Em seguida, as etiquetas da imagem s√£o detectadas e uma lista de etiquetas √© criada.

Por fim, as informa√ß√µes solicitadas sobre a imagem, como o link para a imagem, a data de cria√ß√£o e as etiquetas detectadas, s√£o organizadas em um dicion√°rio e retornadas como uma resposta em formato JSON com o c√≥digo de status 200.

Se ocorrer um erro durante o processo, uma mensagem de erro ser√° retornada como uma resposta em formato JSON com o c√≥digo de status 500.

### **V2 (ROTA 5)**

Fun√ß√£o Lambda que recebe um evento e um contexto e retorna uma resposta em formato JSON contendo informa√ß√µes sobre uma imagem, com √™nfase na detec√ß√£o de faces.

A fun√ß√£o principal, "v2_vision", tenta obter informa√ß√µes sobre uma imagem a partir do evento recebido. Em seguida, as faces na imagem s√£o detectadas e uma lista de informa√ß√µes sobre a posi√ß√£o das faces √© criada.

Dependendo se foram encontradas faces ou n√£o, um valor booleano √© atribu√≠do √† vari√°vel "have_faces". As informa√ß√µes solicitadas sobre a imagem, como o link para a imagem, a data de cria√ß√£o e a lista de informa√ß√µes sobre a posi√ß√£o das faces s√£o organizadas em um dicion√°rio e retornadas como uma resposta em formato JSON com o c√≥digo de status 200.

Se ocorrer um erro durante o processo, uma mensagem de erro ser√° retornada como uma resposta em formato JSON com o c√≥digo de status 500.

### **V3 (ROTA 6)**

Fun√ß√£o chamada "v3_vision" que √© utilizada para detectar faces e emo√ß√µes em uma imagem, retornando uma lista de rostos detectados com as emo√ß√µes classificadas.

A fun√ß√£o come√ßa validando as informa√ß√µes da imagem recebida pelo cliente, caso seja inv√°lida retorna uma mensagem de erro.

Em seguida, a fun√ß√£o detecta as faces na imagem utilizando a fun√ß√£o "get_faces_response" e cria uma lista de rostos detectados com as emo√ß√µes classificadas. Caso n√£o exista nenhuma face detectada, √© adicionado um objeto de rosto vazio com valores nulos.

Depois, a fun√ß√£o cria um objeto de resposta que cont√©m a URL da imagem, a data de cria√ß√£o e a lista de rostos detectados com as emo√ß√µes classificadas.

Por fim, a fun√ß√£o retorna a resposta com sucesso, com um c√≥digo de status 200 e o objeto de resposta convertido em uma string JSON. A resposta tamb√©m √© mostrada no CloudWatch atrav√©s de uma mensagem de log.

## üì§ Deploy

## üìå Considera√ß√µes finais

Em resumo, o projeto envolvendo o uso da plataforma AWS com Amazon Rekognition, S3 e CloudWatch foi muito proveitoso.

Com o Amazon Rekognition √© poss√≠vel analisar imagens e v√≠deos para detec√ß√£o e reconhecimento de objetos, cenas, textos e faces. Com ele, √© poss√≠vel identificar, classificar e indexar imagens para pesquisa e organiza√ß√£o, al√©m de automatizar tarefas como verifica√ß√£o de identidade, monitoramento de seguran√ßa e an√°lise de sentimentos. 

Ao usar o Amazon CloudWatch em conjunto com o Amazon Rekognition, √© poss√≠vel visualizar m√©tricas importantes, como o n√∫mero de solicita√ß√µes de an√°lise de imagem por minuto, o n√∫mero de an√°lises de imagem bem-sucedidas e o tempo m√©dio de resposta.

Portanto, os servi√ßos da AWS, como o Rekognition, fornecem recursos poderosos de processamento de imagem e reconhecimento de padr√µes para diversas aplica√ß√µes. Ao integrar o Amazon CloudWatch, √© poss√≠vel monitorar e analisar o desempenho das aplica√ß√µes. Essa integra√ß√£o √© importante para garantir a qualidade do servi√ßo oferecido, bem como para auxiliar no gerenciamento de custos e na tomada de decis√µes estrat√©gicas.

## üë§ Equipe

- [Edival√ßo Ara√∫jo](https://github.com/EdivalcoAraujo)
- [Humberto Sampaio](https://github.com/Humbert010)
- [Luan Ferreira](https://github.com/fluanbrito)
- [Mylena Soares](https://github.com/mylensoares)
